{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../feature/stacking_pkl_file/2leve_lgb_stacking3.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/Capsule.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/capsule_all_shuffle.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/capsule_shuffle.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/cnn.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/mlp.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/mlp_shuffle.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/pseudo_rnn2.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn7879.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_all_shuffle_all.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_cnn.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_pseudo1.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_shuffle1.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_shuffle2.pkl\n",
      "(102277, 19) (102277, 19)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../feature/stacking_pkl_file/*')):\n",
    "    if 'fm2.pkl' in feat or 'ligbm' in  feat :\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../feature/other_features/features-vinson/bnb_prob_10w.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/lr_prob.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/lr_prob_0.778620.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/mnb_prob_10w.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/nn_ensemble_0.775597.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/svc_prob.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/svc_prob_0.778881.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/word_fasttext_0.760225.csv\n",
      "(102277, 19) (102277, 19)\n",
      "(102277, 418)\n"
     ]
    }
   ],
   "source": [
    "for feat in sorted(glob.glob('../feature/other_features/features-vinson/*')):\n",
    "    if 'fm2.pkl' in feat or 'w2v' in feat or 'lda' in feat or 'lsi' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    file=pd.read_csv(feat)\n",
    "    a = file.iloc[:102277,:]\n",
    "    b = file.iloc[102277:,:]\n",
    "    a = a.values\n",
    "    b = b.values\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/check.py:17: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"../input/new_data/train_set.csv\")\n",
    "y=(train[\"class\"]-1).astype(int)\n",
    "del train\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "train_y=np_utils.to_categorical(y,num_classes=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_f1_score(data, y_hat):\n",
    "    y_true = data\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return f1_score(y_true, y_hat, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,c_bytree=0.9,s_sample=0.9):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred, val_pred = np.zeros((102277,20)), np.zeros((102277,20))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_f1_l,all_val_f1_l = 0,0\n",
    "    \n",
    "    for i in range(19):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_f1_l,train_f1_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test =xgb.DMatrix(test_x)\n",
    "            \n",
    "            d_train = xgb.DMatrix(curr_x, curr_y[:,i])\n",
    "            d_valid = xgb.DMatrix(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "        \n",
    "            model.fit(curr_x, curr_y[:,i], eval_set=(hold_out_x, hold_out_y[:,i]), use_best_model=True, verbose=False)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            train_pred = model.predict(curr_x)\n",
    "            val_pred[test_index, i] = model.predict(hold_out_x)\n",
    "            curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "            curr_val_loss = log_loss(hold_out_y[:,i],val_pred[test_index, i])\n",
    "\n",
    "            curr_train_f1 = self_f1_score(curr_y[:,i],train_pred)\n",
    "            curr_val_f1 = self_f1_score(hold_out_y[:,i],val_pred[test_index, i])\n",
    "\n",
    "            print('ls',curr_train_loss,curr_val_loss,'f1',curr_train_f1,curr_val_f1)\n",
    "            val_loss_l += curr_val_loss\n",
    "            train_loss_l += curr_train_loss\n",
    "            val_f1_l += curr_val_f1\n",
    "            train_f1_l += curr_train_f1\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_f1_l = train_f1_l/k\n",
    "        val_f1_l = val_f1_l/k\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class f1 train',train_f1_l,'f1 val',val_f1_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/19\n",
    "        all_val_loss_l += val_loss_l/19\n",
    "        all_train_f1_l += train_f1_l/19\n",
    "        all_val_f1_l += val_f1_l/19\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all f1 avg',all_train_f1_l,all_val_f1_l)\n",
    "    print('=======================================================')\n",
    "    return val_pred, test_pred\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

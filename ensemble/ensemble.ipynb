{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../feature/stacking_pkl_file/Capsule.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/capsule_all_shuffle.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/capsule_shuffle.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/cnn.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/dpcnn2000.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/mlp.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/mlp_shuffle.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/pseudo_rnn2.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn2000.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn7879.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_all_shuffle_all.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_cnn.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_pseudo1.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_shuffle1.pkl\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/stacking_pkl_file/rnn_shuffle2.pkl\n",
      "(102277, 19) (102277, 19)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../feature/stacking_pkl_file/*.pkl')):\n",
    "    if 'fm2.pkl' in feat or 'ligbm' in  feat or '2leve' in  feat :\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "    \n",
    "# train_x = np.nan_to_num(np.hstack(train_x))\n",
    "# test_x = np.nan_to_num(np.hstack(test_x))\n",
    "# print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "\n",
    "# list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "# train_y = train[list_classes].values.astype('int')\n",
    "# print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../feature/other_features/features-vinson/bnb_prob_10w.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/lr_prob.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/lr_prob_0.778620.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/mnb_prob_10w.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/nn_ensemble_0.775597.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/svc_prob.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/svc_prob_0.778881.csv\n",
      "(102277, 19) (102277, 19)\n",
      "file path ../feature/other_features/features-vinson/word_fasttext_0.760225.csv\n",
      "(102277, 19) (102277, 19)\n",
      "(102277, 437)\n"
     ]
    }
   ],
   "source": [
    "for feat in sorted(glob.glob('../feature/other_features/features-vinson/*.csv')):\n",
    "    if 'fm2.pkl' in feat or 'w2v' in feat or 'lda' in feat or 'lsi' in feat or 'xgb' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    file=pd.read_csv(feat)\n",
    "    a = file.iloc[:102277,:]\n",
    "    b = file.iloc[102277:,:]\n",
    "    a = a.values\n",
    "    b = b.values\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"../input/new_data/train_set.csv\")\n",
    "y=(train[\"class\"]-1).astype(int)\n",
    "del train\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import np_utils\n",
    "train_y=np_utils.to_categorical(y,num_classes=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_f1_score(data, y_hat):\n",
    "    y_true = data\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return f1_score(y_true, y_hat, average='macro')\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat, average='macro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss'):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred, val_pred = np.zeros((102277,20)), np.zeros((102277,20))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_f1_l,all_val_f1_l = 0,0\n",
    "    \n",
    "    for i in range(19):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_f1_l,train_f1_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "            # share params\n",
    "            params = {\n",
    "                    'application': 'binary',\n",
    "                    'num_leaves': 15,\n",
    "                    #'lambda_l1': 1,\n",
    "                    'lambda_l2': 1.0,\n",
    "                    'max_depth': 4,\n",
    "                    #'scale_pos_weight':0.9,\n",
    "                    'metric': met, # or auc\n",
    "                    'data_random_seed': 2,\n",
    "                    'learning_rate':lr,\n",
    "                    'bagging_fraction': bagging_fraction,\n",
    "                    'bagging_freq':bag_frec,\n",
    "                    'feature_fraction': feature_fraction,\n",
    "                    'num_threads':4\n",
    "\n",
    "                    }\n",
    "            if met == 'auc':\n",
    "                s_round = 100\n",
    "            else:\n",
    "                s_round = 50\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "#                       feval=lgb_f1_score,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            train_pred = model.predict(curr_x)\n",
    "            val_pred[test_index, i] = model.predict(hold_out_x)\n",
    "            curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "            curr_val_loss = log_loss(hold_out_y[:,i],val_pred[test_index, i])\n",
    "\n",
    "            curr_train_f1 = self_f1_score(curr_y[:,i],train_pred)\n",
    "            curr_val_f1 = self_f1_score(hold_out_y[:,i],val_pred[test_index, i])\n",
    "\n",
    "            print('ls',curr_train_loss,curr_val_loss,'f1',curr_train_f1,curr_val_f1)\n",
    "            val_loss_l += curr_val_loss\n",
    "            train_loss_l += curr_train_loss\n",
    "            val_f1_l += curr_val_f1\n",
    "            train_f1_l += curr_train_f1\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_f1_l = train_f1_l/k\n",
    "        val_f1_l = val_f1_l/k\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class f1 train',train_f1_l,'f1 val',val_f1_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/19\n",
    "        all_val_loss_l += val_loss_l/19\n",
    "        all_train_f1_l += train_f1_l/19\n",
    "        all_val_f1_l += val_f1_l/19\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all f1 avg',all_train_f1_l,all_val_f1_l)\n",
    "    print('=======================================================')\n",
    "    return val_pred, test_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py:186: UserWarning: Usage subset(sliced data) of np.ndarray is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  warnings.warn(\"Usage subset(sliced data) of np.ndarray is not recommended due to it will double the peak memory cost in LightGBM.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.08827563701288117 0.09553616387429105 f1 0.8043222755634124 0.7994799611204153\n",
      "1 fold: ls 0.08657027530838257 0.09877635784900357 f1 0.8067430705685795 0.7896281263712155\n",
      "2 fold: ls 0.08881709534546858 0.09729638105085076 f1 0.8049214364250823 0.8037576017451533\n",
      "3 fold: ls 0.08017932511270662 0.09831054426410638 f1 0.8204449311485509 0.7942332855894818\n",
      "4 fold: ls 0.07941667528772789 0.0975385637618827 f1 0.8196513936465029 0.7943812764818012\n",
      "this class avg train 0.08465180161343337 avg val 0.09749160216002689\n",
      "this class f1 train 0.8112166214704256 f1 val 0.7962960502616134\n",
      "========================\n",
      "0 fold: ls 0.024078599889330036 0.028995300020772382 f1 0.9138724808527812 0.9035573194311969\n",
      "1 fold: ls 0.0218544243459654 0.03236329900675408 f1 0.9186785020445116 0.8936851796734968\n",
      "2 fold: ls 0.023874336909500783 0.029480033848739182 f1 0.9154258963494506 0.9042401162149432\n",
      "3 fold: ls 0.022012829601353045 0.03255242649172084 f1 0.9191003363656742 0.8932971667559146\n",
      "4 fold: ls 0.02359262807802929 0.030313245364832285 f1 0.9156739059957753 0.8989062616972769\n",
      "this class avg train 0.023082563764835713 avg val 0.030740860946563753\n",
      "this class f1 train 0.9165502243216386 f1 val 0.8987372087545659\n",
      "========================\n",
      "0 fold: ls 0.02216555916742234 0.04173992951614127 f1 0.972461861402778 0.9543371837751262\n",
      "1 fold: ls 0.03434585185683577 0.046024144975460916 f1 0.9602351716703448 0.9539494511919283\n",
      "2 fold: ls 0.028698320843234825 0.04031294964942566 f1 0.9647310290773882 0.9551925036467415\n",
      "3 fold: ls 0.034561365642246274 0.037748481185035924 f1 0.9597704757114489 0.9572405942339736\n",
      "4 fold: ls 0.024899530722970777 0.0417506703497805 f1 0.9690610780002313 0.9538707083035813\n",
      "this class avg train 0.028934125646542 avg val 0.04151523513516885\n",
      "this class f1 train 0.9652519231724381 f1 val 0.9549180882302701\n",
      "========================\n",
      "0 fold: ls 0.019203205394216664 0.027021469261041896 f1 0.9469439653996468 0.9322669832762946\n",
      "1 fold: ls 0.020716331654196972 0.028976695671571347 f1 0.9455175666964528 0.9321343448428069\n",
      "2 fold: ls 0.017319586052116347 0.026026246649257102 f1 0.9535140217202022 0.9332609720100498\n",
      "3 fold: ls 0.019998726080740006 0.026058097544358737 f1 0.9457608833934916 0.9352246840938576\n",
      "4 fold: ls 0.01988036166570464 0.028895115752275605 f1 0.9466101984972706 0.9289289293870275\n",
      "this class avg train 0.019423642169394927 avg val 0.02739552497570094\n",
      "this class f1 train 0.9476693271414127 f1 val 0.9323631827220075\n",
      "========================\n",
      "0 fold: ls 0.015914580592722747 0.01984707582712689 f1 0.9397692150381436 0.9292845309110367\n",
      "1 fold: ls 0.014000069802528603 0.02311697190885724 f1 0.9478942508514068 0.9177218495768269\n",
      "2 fold: ls 0.014489564259426881 0.021055288581611972 f1 0.9442703465245399 0.9251809415519929\n",
      "3 fold: ls 0.016524286842873444 0.023716445880716534 f1 0.9393624132894537 0.9177217589971225\n",
      "4 fold: ls 0.014541567734359195 0.02273326560863324 f1 0.9432906210004462 0.9134759178163072\n",
      "this class avg train 0.015094013846382173 avg val 0.022093809561389174\n",
      "this class f1 train 0.9429173693407981 f1 val 0.9206769997706573\n",
      "========================\n",
      "0 fold: ls 0.023046731903813043 0.02736554381050303 f1 0.9683409375079978 0.9665292739707441\n",
      "1 fold: ls 0.022053781647199868 0.029732041788693677 f1 0.9700456743078573 0.9642484363924455\n",
      "2 fold: ls 0.02315540849943138 0.030192795523011223 f1 0.9686192323686086 0.9644729673081351\n",
      "3 fold: ls 0.022195580892912178 0.03305048989426794 f1 0.9698839548562211 0.9618554194522922\n",
      "4 fold: ls 0.022033963983101264 0.03167952178356686 f1 0.9703965852271041 0.9605846780489795\n",
      "this class avg train 0.022497093385291544 avg val 0.030404078560008548\n",
      "this class f1 train 0.9694572768535578 f1 val 0.9635381550345195\n",
      "========================\n",
      "0 fold: ls 0.036222849780506536 0.046549927892878755 f1 0.8729772640291407 0.8454917484812674\n",
      "1 fold: ls 0.036411147907684835 0.04504548478035914 f1 0.8743613709053366 0.8509055756201396\n",
      "2 fold: ls 0.034209674785922274 0.04228070622047825 f1 0.8797183222139818 0.8641661386024277\n",
      "3 fold: ls 0.03365048265372114 0.04361959874408948 f1 0.8785046927857666 0.86182198537522\n",
      "4 fold: ls 0.03690415970237102 0.04380491067144539 f1 0.8697116724013055 0.8642467190689852\n",
      "this class avg train 0.03547966296604116 avg val 0.044260125661850204\n",
      "this class f1 train 0.8750546644671063 f1 val 0.8573264334296079\n",
      "========================\n",
      "0 fold: ls 0.06342427032793756 0.07351942190723286 f1 0.8887065432164762 0.8818297584695634\n",
      "1 fold: ls 0.06853150839001189 0.08129160750411384 f1 0.8796518618555295 0.8692460805564144\n",
      "2 fold: ls 0.06624071317718234 0.08023038196353686 f1 0.8857175849679939 0.8645667530558271\n",
      "3 fold: ls 0.07208868836416289 0.08061960029900962 f1 0.8784494373481314 0.8707654120443589\n",
      "4 fold: ls 0.07038059993407979 0.08237823870054493 f1 0.8807397744298242 0.8611581114600744\n",
      "this class avg train 0.0681331560386749 avg val 0.07960785007488762\n",
      "this class f1 train 0.882653040363591 f1 val 0.8695132231172475\n",
      "========================\n",
      "0 fold: ls 0.018500611865016583 0.02529327555160993 f1 0.9768666640834383 0.970539930790461\n",
      "1 fold: ls 0.015126326559166866 0.022866885633817714 f1 0.9802451734675022 0.9737784513746088\n",
      "2 fold: ls 0.018703463457476373 0.03103191649099596 f1 0.9777831384846081 0.9672259994212185\n",
      "3 fold: ls 0.017665591208931162 0.024386355669161447 f1 0.9771863656294997 0.9726081296906416\n",
      "4 fold: ls 0.01993184810180396 0.029868201647705785 f1 0.9755228670240852 0.9715653264517206\n",
      "this class avg train 0.017985568238478987 avg val 0.026689326998658162\n",
      "this class f1 train 0.9775208417378266 f1 val 0.9711435675457301\n",
      "========================\n",
      "0 fold: ls 0.05889260532283095 0.06777316109067875 f1 0.8686212913168097 0.8540859219741683\n",
      "1 fold: ls 0.05702271037453017 0.06471286471451332 f1 0.8678781823472033 0.8607278652501174\n",
      "2 fold: ls 0.05930254817759441 0.06936289423526622 f1 0.8681436228462311 0.8495457540952739\n",
      "3 fold: ls 0.05883647932979446 0.06988657893803009 f1 0.8686844640792658 0.8506480128937582\n",
      "4 fold: ls 0.06024631292505877 0.06704553646798578 f1 0.8646754212213805 0.8510835994277836\n",
      "this class avg train 0.05886013122596175 avg val 0.06775620708929483\n",
      "this class f1 train 0.867600596362178 f1 val 0.8532182307282202\n",
      "========================\n",
      "0 fold: ls 0.036477850283334244 0.04973720408576446 f1 0.8872397986846465 0.8524261653820872\n",
      "1 fold: ls 0.03883285878974456 0.04614330813238932 f1 0.8786895735705054 0.8594958327353315\n",
      "2 fold: ls 0.03827699443552614 0.04741809218974064 f1 0.8821560899517897 0.8641444468180141\n",
      "3 fold: ls 0.03826197299466004 0.04838318819108974 f1 0.881107848747809 0.8599729778418304\n",
      "4 fold: ls 0.03055177496983257 0.043141370317248476 f1 0.9033506175106524 0.8810002809760356\n",
      "this class avg train 0.03648029029461951 avg val 0.04696463258324653\n",
      "this class f1 train 0.8865087856930807 f1 val 0.8634079407506597\n",
      "========================\n",
      "0 fold: ls 0.06439102627860198 0.07097884870026976 f1 0.8589835121831308 0.8564961050711128\n",
      "1 fold: ls 0.0653958412995134 0.070313905984765 f1 0.85934311856016 0.8542242351657279\n",
      "2 fold: ls 0.05828326396621505 0.07377084344546819 f1 0.8715298691955975 0.8471111107202927\n",
      "3 fold: ls 0.0652113058035447 0.07529641818116188 f1 0.8621652662926083 0.8461650982562041\n",
      "4 fold: ls 0.06458718499709802 0.07546422515693031 f1 0.8592515612387658 0.8515885974077132\n",
      "this class avg train 0.06357372446899463 avg val 0.07316484829371903\n",
      "this class f1 train 0.8622546654940525 f1 val 0.8511170293242101\n",
      "========================\n",
      "0 fold: ls 0.06924076876671155 0.07580142775988173 f1 0.8998400038309666 0.8946230108175386\n",
      "1 fold: ls 0.07019130182735184 0.07841170927797543 f1 0.9001080087794013 0.887930129102961\n",
      "2 fold: ls 0.0695018644957807 0.08111622462092807 f1 0.9020322819544613 0.8899626052217704\n",
      "3 fold: ls 0.06498830051085362 0.07696068189283325 f1 0.9048809514116702 0.894097440890143\n",
      "4 fold: ls 0.06621773935541093 0.07674863311391387 f1 0.9042516377129276 0.8948153655858685\n",
      "this class avg train 0.06802799499122172 avg val 0.07780773533310648\n",
      "this class f1 train 0.9022225767378854 f1 val 0.8922857103236563\n",
      "========================\n",
      "0 fold: ls 0.04999242732128033 0.059699695598193755 f1 0.9172842998360552 0.9055518798083151\n",
      "1 fold: ls 0.046373975318827 0.054805824089786265 f1 0.9227083052462084 0.9137131318409177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold: ls 0.04936849461141498 0.0594056258789206 f1 0.9188920908357143 0.8999406558669256\n",
      "3 fold: ls 0.049601417257087804 0.060595329909789546 f1 0.918950635457121 0.9043372428641226\n",
      "4 fold: ls 0.04819868363151262 0.06091689271508531 f1 0.9185476624366806 0.9083890166922003\n",
      "this class avg train 0.04870699962802454 avg val 0.0590846736383551\n",
      "this class f1 train 0.9192765987623558 f1 val 0.9063863854144962\n",
      "========================\n",
      "0 fold: ls 0.025842413181468883 0.031953902163249795 f1 0.9652093361930522 0.9604460777317545\n",
      "1 fold: ls 0.02514372216349045 0.0314766734781418 f1 0.9669257643847755 0.9599539282346058\n",
      "2 fold: ls 0.025990628438587637 0.03659816193842366 f1 0.9658653113943834 0.9532230104503185\n",
      "3 fold: ls 0.02650726287590244 0.03511565768984758 f1 0.9652708198303492 0.9620627565069513\n",
      "4 fold: ls 0.027157055141466154 0.03455296424411928 f1 0.9644849470857366 0.9584981762462647\n",
      "this class avg train 0.02612821636018311 avg val 0.033939471902756424\n",
      "this class f1 train 0.9655512357776594 f1 val 0.958836789833979\n",
      "========================\n",
      "0 fold: ls 0.016996087932780964 0.027161012161055986 f1 0.942024522692686 0.9088622125097856\n",
      "1 fold: ls 0.016577535388881796 0.024945058613695847 f1 0.9467221896254516 0.9225642991023482\n",
      "2 fold: ls 0.015573683964212043 0.023460701515189274 f1 0.9510754837778856 0.9223427274926075\n",
      "3 fold: ls 0.013382688866537635 0.02568812160880881 f1 0.9593686009097 0.9206201921136572\n",
      "4 fold: ls 0.01485902529776291 0.02384101570438209 f1 0.954754460824765 0.92020149200187\n",
      "this class avg train 0.015477804290035068 avg val 0.025019181920626403\n",
      "this class f1 train 0.9507890515660977 f1 val 0.9189181846440537\n",
      "========================\n",
      "0 fold: ls 0.02858800835985818 0.03482263652135543 f1 0.900996157690948 0.8826821648731971\n",
      "1 fold: ls 0.02807040988364123 0.037216698631635174 f1 0.9040131502655715 0.8713523847856711\n",
      "2 fold: ls 0.027848553990550994 0.0396361566953334 f1 0.9023948959459834 0.8800556461763284\n",
      "3 fold: ls 0.028090801605161336 0.03289771483927959 f1 0.8998924718118484 0.8962037501340734\n",
      "4 fold: ls 0.028614221888987306 0.03481404851599392 f1 0.9003421579537828 0.8827833830859491\n",
      "this class avg train 0.028242399145639807 avg val 0.0358774510407195\n",
      "this class f1 train 0.9015277667336268 f1 val 0.8826154658110438\n",
      "========================\n",
      "0 fold: ls 0.03506895206488238 0.041122853505139806 f1 0.9491824701958582 0.9429078408460341\n",
      "1 fold: ls 0.03503891437737292 0.04272540561731241 f1 0.9499453444260165 0.942979008902701\n",
      "2 fold: ls 0.034686000756913006 0.04262398942241778 f1 0.9516078520192846 0.9414670354279893\n",
      "3 fold: ls 0.03485176316792924 0.04516004500364028 f1 0.95086229911921 0.9381125192524106\n",
      "4 fold: ls 0.033837047805446885 0.042426366231277435 f1 0.9508209360687101 0.9441014000987065\n",
      "this class avg train 0.034696535634508884 avg val 0.04281173195595754\n",
      "this class f1 train 0.9504837803658159 f1 val 0.9419135609055683\n",
      "========================\n",
      "0 fold: ls 0.0839339160048205 0.0936013130899156 f1 0.8239424895175027 0.814050783591317\n",
      "1 fold: ls 0.07991415112535759 0.08958713713490683 f1 0.8262492982083882 0.8207266666454209\n",
      "2 fold: ls 0.08214790703547861 0.09543653299110633 f1 0.8273938947659576 0.8084747278426664\n",
      "3 fold: ls 0.0779369481718536 0.08971106448213016 f1 0.8291937735512199 0.8091097363913247\n",
      "4 fold: ls 0.08309831387501601 0.09415953681386237 f1 0.8232441344240311 0.8114704303447243\n",
      "this class avg train 0.08140624724250527 avg val 0.09249911690238426\n",
      "this class f1 train 0.8260047180934199 f1 val 0.8127664689630907\n",
      "========================\n",
      "all loss avg 0.04088852478688259 0.050269656038653694\n",
      "all f1 avg 0.9116058454976299 0.8971567723981684\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_train, lgb_res = simple_ens('lgb',5,233,0.05,0.6)\n",
    "##all loss avg 0.04941417146346469 0.05321999547256359\n",
    "# all f1 avg 0.8965591064486441 0.8915637951017253\n",
    "#######################7982<lb<7985\n",
    "\n",
    "#all loss avg 0.04911572582626101 0.052974216091397554\n",
    "# all f1 avg 0.8970629823676124 0.8922944850147942\n",
    "\n",
    "# all loss avg 0.0414203008656468 0.052978859434622785\n",
    "# all f1 avg 0.9103949564755508 0.8924077581728779\n",
    "\n",
    "# all loss avg 0.04539159633943475 0.05255053671449584\n",
    "# all f1 avg 0.9029697229659733 0.8934845973558836\n",
    "\n",
    "#all loss avg 0.04494700768702617 0.052254864071516055\n",
    "# all f1 avg 0.9040207644649525 0.8939220820764944\n",
    "\n",
    "# all loss avg 0.04353723194221981 0.051953447288746665\n",
    "# all f1 avg 0.9064007590628727 0.8947753048612783\n",
    "# 7940810057586943\n",
    "\n",
    "# all loss avg 0.041791878911084705 0.0502085007027876\n",
    "# all f1 avg 0.9094424575179055 0.8970108064794169\n",
    "#0.7956058839820572\n",
    "#0.8979044788487316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../feature/2leve_lgb_stacking8.pkl','wb') as fout:\n",
    "    pickle.dump([lgb_train,lgb_res],fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../input/new_data/test_set.csv'\n",
    "test = pd.read_csv(test_dir)\n",
    "test_id = test[[\"id\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102277, 1)\n",
      "(102277, 1)\n"
     ]
    }
   ],
   "source": [
    "preds=np.argmax(lgb_res,axis=1)\n",
    "test_pred=pd.DataFrame(preds)\n",
    "test_pred.columns=[\"class\"]\n",
    "test_pred[\"class\"]=(test_pred[\"class\"]+1).astype(int)\n",
    "print(test_pred.shape)\n",
    "print(test_id.shape)\n",
    "test_pred[\"id\"]=list(test_id[\"id\"])\n",
    "test_pred[[\"id\",\"class\"]].to_csv('../output/lgbstacknnx3.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  4, 13, ...,  6, 14, 13])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"class_prob_%s\"%i for i in range(1,21)]\n",
    "df_lgb = pd.DataFrame(lgb_res, columns=name)\n",
    "df_lgb = df_lgb.drop('class_prob_20', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_lgb.to_csv('../pro/stacking_lgbx3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_prob_1</th>\n",
       "      <th>class_prob_2</th>\n",
       "      <th>class_prob_3</th>\n",
       "      <th>class_prob_4</th>\n",
       "      <th>class_prob_5</th>\n",
       "      <th>class_prob_6</th>\n",
       "      <th>class_prob_7</th>\n",
       "      <th>class_prob_8</th>\n",
       "      <th>class_prob_9</th>\n",
       "      <th>class_prob_10</th>\n",
       "      <th>class_prob_11</th>\n",
       "      <th>class_prob_12</th>\n",
       "      <th>class_prob_13</th>\n",
       "      <th>class_prob_14</th>\n",
       "      <th>class_prob_15</th>\n",
       "      <th>class_prob_16</th>\n",
       "      <th>class_prob_17</th>\n",
       "      <th>class_prob_18</th>\n",
       "      <th>class_prob_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.990493</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.048086</td>\n",
       "      <td>0.003451</td>\n",
       "      <td>0.090661</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.016101</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.057101</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.015374</td>\n",
       "      <td>0.043277</td>\n",
       "      <td>0.674879</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.024633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007421</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.957149</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.002011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.042360</td>\n",
       "      <td>0.004619</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.905513</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.014645</td>\n",
       "      <td>0.009018</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.003913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022126</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.073293</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.007860</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.900470</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>0.033831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.027287</td>\n",
       "      <td>0.150816</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.072876</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.030359</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.084286</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.567641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.993834</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.116432</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.018618</td>\n",
       "      <td>0.150082</td>\n",
       "      <td>0.014089</td>\n",
       "      <td>0.153835</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.515543</td>\n",
       "      <td>0.023741</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.018156</td>\n",
       "      <td>0.078827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.052592</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.281222</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.342549</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.315227</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.003585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.309132</td>\n",
       "      <td>0.317520</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.014201</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.237276</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.020436</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.980133</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.015126</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.100095</td>\n",
       "      <td>0.837777</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.012250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.994893</td>\n",
       "      <td>0.002526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.998649</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.997448</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.677820</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.339740</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.635491</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.005774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.996934</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.108066</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.018776</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.026711</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.358461</td>\n",
       "      <td>0.262274</td>\n",
       "      <td>0.100263</td>\n",
       "      <td>0.004576</td>\n",
       "      <td>0.035627</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.056439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.998015</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.089409</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.159656</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.649393</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.062489</td>\n",
       "      <td>0.008563</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.060520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.009711</td>\n",
       "      <td>0.865489</td>\n",
       "      <td>0.013792</td>\n",
       "      <td>0.018470</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>0.037148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.027463</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.695518</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.311241</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.004006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.014762</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.010956</td>\n",
       "      <td>0.522012</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.507260</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.007748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.002899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.056011</td>\n",
       "      <td>0.922620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102247</th>\n",
       "      <td>0.010127</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.031078</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.957709</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102248</th>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.882987</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.058030</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.002504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102249</th>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.814016</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102250</th>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.988637</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102251</th>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.992607</td>\n",
       "      <td>0.004398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102252</th>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.153063</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.125178</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.060553</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.750395</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.000760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102253</th>\n",
       "      <td>0.042093</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.050338</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001889</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.926154</td>\n",
       "      <td>0.009977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102254</th>\n",
       "      <td>0.018986</td>\n",
       "      <td>0.904875</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.015787</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.005453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102255</th>\n",
       "      <td>0.022291</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>0.019155</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.025164</td>\n",
       "      <td>0.019383</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.698647</td>\n",
       "      <td>0.041467</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.037494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102256</th>\n",
       "      <td>0.962063</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.013022</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102257</th>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.996174</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102258</th>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.010454</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.875027</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.007769</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.052710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102259</th>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.026564</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.095305</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.791936</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.022199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102260</th>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.053847</td>\n",
       "      <td>0.903328</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102261</th>\n",
       "      <td>0.014231</td>\n",
       "      <td>0.025711</td>\n",
       "      <td>0.034120</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.022570</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>0.003732</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.139468</td>\n",
       "      <td>0.132251</td>\n",
       "      <td>0.050964</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.042260</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.397146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102262</th>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.867443</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.065033</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.038965</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.032211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102263</th>\n",
       "      <td>0.007094</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.050255</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.031398</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.832055</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.025870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102264</th>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.995670</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102265</th>\n",
       "      <td>0.189612</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.012405</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.023503</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.048597</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>0.688654</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.009226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102266</th>\n",
       "      <td>0.154432</td>\n",
       "      <td>0.023365</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.009906</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.249928</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>0.016842</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.224741</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.030618</td>\n",
       "      <td>0.263080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102267</th>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.989922</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102268</th>\n",
       "      <td>0.105625</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.855179</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.043407</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.002883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102269</th>\n",
       "      <td>0.102175</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.140040</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.025910</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>0.702694</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.003947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102270</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.986916</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102271</th>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.998145</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102272</th>\n",
       "      <td>0.011511</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.061904</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.095558</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.018718</td>\n",
       "      <td>0.036094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102273</th>\n",
       "      <td>0.023107</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.597092</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.326504</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.106505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102274</th>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.126234</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.747059</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.034813</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102275</th>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.962072</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102276</th>\n",
       "      <td>0.025796</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001101</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.835382</td>\n",
       "      <td>0.094020</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.008217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102277 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class_prob_1  class_prob_2  class_prob_3  class_prob_4  class_prob_5  \\\n",
       "0           0.002243      0.000325      0.000705      0.003167      0.989950   \n",
       "1           0.002102      0.000295      0.000464      0.990493      0.000269   \n",
       "2           0.048086      0.003451      0.090661      0.002261      0.016101   \n",
       "3           0.000416      0.000195      0.000306      0.993631      0.000303   \n",
       "4           0.007421      0.000248      0.001962      0.003248      0.957149   \n",
       "5           0.042360      0.004619      0.004972      0.000883      0.905513   \n",
       "6           0.022126      0.001004      0.004279      0.004812      0.000478   \n",
       "7           0.027287      0.150816      0.002845      0.001222      0.003192   \n",
       "8           0.000297      0.000154      0.993834      0.000148      0.000278   \n",
       "9           0.116432      0.002801      0.001755      0.002846      0.002998   \n",
       "10          0.052592      0.000771      0.000533      0.000585      0.001660   \n",
       "11          0.309132      0.317520      0.005020      0.001153      0.014201   \n",
       "12          0.003322      0.000826      0.000428      0.000234      0.980133   \n",
       "13          0.015126      0.000443      0.001608      0.001519      0.000614   \n",
       "14          0.000265      0.000165      0.000228      0.000167      0.000260   \n",
       "15          0.000553      0.000188      0.000236      0.000139      0.000265   \n",
       "16          0.000238      0.000165      0.000261      0.000140      0.000289   \n",
       "17          0.000260      0.000161      0.000302      0.000141      0.000266   \n",
       "18          0.001547      0.000368      0.677820      0.002328      0.001408   \n",
       "19          0.001293      0.000218      0.000381      0.000876      0.000364   \n",
       "20          0.000417      0.000172      0.000230      0.000139      0.000253   \n",
       "21          0.108066      0.000490      0.018776      0.004094      0.002564   \n",
       "22          0.000271      0.000174      0.000264      0.000144      0.000271   \n",
       "23          0.089409      0.000276      0.007051      0.000527      0.000953   \n",
       "24          0.009711      0.865489      0.013792      0.018470      0.003272   \n",
       "25          0.000384      0.000425      0.000389      0.000149      0.000275   \n",
       "26          0.000856      0.000187      0.695518      0.000385      0.000926   \n",
       "27          0.014762      0.001428      0.002216      0.000881      0.000532   \n",
       "28          0.013703      0.000446      0.000508      0.943848      0.000437   \n",
       "29          0.001529      0.000302      0.000446      0.000196      0.002862   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "102247      0.010127      0.000246      0.000273      0.000270      0.000971   \n",
       "102248      0.020077      0.001054      0.001206      0.000297      0.002634   \n",
       "102249      0.016704      0.000249      0.000912      0.000377      0.001916   \n",
       "102250      0.001013      0.988637      0.000397      0.003444      0.001112   \n",
       "102251      0.000570      0.000177      0.000284      0.000162      0.000268   \n",
       "102252      0.021049      0.000305      0.002783      0.001736      0.153063   \n",
       "102253      0.042093      0.003008      0.000773      0.000267      0.000558   \n",
       "102254      0.018986      0.904875      0.002518      0.015787      0.004009   \n",
       "102255      0.022291      0.000417      0.042479      0.019155      0.001915   \n",
       "102256      0.962063      0.000237      0.002032      0.000181      0.002603   \n",
       "102257      0.000264      0.000162      0.000739      0.000158      0.000278   \n",
       "102258      0.007410      0.001595      0.002587      0.000990      0.001886   \n",
       "102259      0.000543      0.001200      0.026564      0.000273      0.000318   \n",
       "102260      0.013300      0.000215      0.000594      0.004241      0.000798   \n",
       "102261      0.014231      0.025711      0.034120      0.002825      0.002644   \n",
       "102262      0.010385      0.867443      0.002077      0.065033      0.004223   \n",
       "102263      0.007094      0.003920      0.003612      0.003088      0.002837   \n",
       "102264      0.000439      0.000222      0.000371      0.000207      0.000264   \n",
       "102265      0.189612      0.002507      0.000776      0.002302      0.001146   \n",
       "102266      0.154432      0.023365      0.033830      0.001123      0.001512   \n",
       "102267      0.000390      0.000190      0.989922      0.000145      0.000298   \n",
       "102268      0.105625      0.001657      0.008404      0.000415      0.004061   \n",
       "102269      0.102175      0.000828      0.001075      0.000983      0.140040   \n",
       "102270      0.000355      0.000152      0.009502      0.000194      0.000295   \n",
       "102271      0.000284      0.000161      0.000322      0.000140      0.000258   \n",
       "102272      0.011511      0.021176      0.002936      0.001376      0.003132   \n",
       "102273      0.023107      0.003881      0.003098      0.010983      0.002775   \n",
       "102274      0.000604      0.000226      0.006373      0.126234      0.000702   \n",
       "102275      0.006313      0.000371      0.000309      0.001418      0.000335   \n",
       "102276      0.025796      0.002465      0.001381      0.000649      0.002038   \n",
       "\n",
       "        class_prob_6  class_prob_7  class_prob_8  class_prob_9  class_prob_10  \\\n",
       "0           0.001370      0.000524      0.000191      0.000360       0.000538   \n",
       "1           0.000269      0.000282      0.000248      0.000218       0.000324   \n",
       "2           0.002078      0.010597      0.057101      0.005158       0.005243   \n",
       "3           0.000304      0.000210      0.000234      0.000195       0.000369   \n",
       "4           0.000700      0.007263      0.000243      0.000522       0.004221   \n",
       "5           0.004797      0.000374      0.012448      0.002398       0.014645   \n",
       "6           0.000994      0.000616      0.002421      0.000458       0.073293   \n",
       "7           0.009782      0.072876      0.010019      0.003041       0.018198   \n",
       "8           0.000350      0.000192      0.000134      0.000251       0.000239   \n",
       "9           0.003100      0.018618      0.150082      0.014089       0.153835   \n",
       "10          0.000462      0.001270      0.281222      0.000401       0.342549   \n",
       "11          0.008026      0.004052      0.237276      0.004414       0.064600   \n",
       "12          0.000268      0.000282      0.000191      0.000260       0.001550   \n",
       "13          0.000687      0.000496      0.000884      0.000365       0.001235   \n",
       "14          0.000213      0.000187      0.000134      0.000198       0.000240   \n",
       "15          0.000229      0.000192      0.000152      0.000301       0.000241   \n",
       "16          0.000167      0.000258      0.000139      0.998649       0.000254   \n",
       "17          0.000171      0.000226      0.000127      0.997448       0.000237   \n",
       "18          0.002358      0.002521      0.000219      0.003480       0.000792   \n",
       "19          0.000233      0.005500      0.000302      0.000740       0.002591   \n",
       "20          0.000170      0.000223      0.000128      0.996934       0.000245   \n",
       "21          0.005689      0.015479      0.005462      0.026711       0.003063   \n",
       "22          0.000222      0.000207      0.000128      0.998015       0.000258   \n",
       "23          0.001150      0.159656      0.002275      0.649393       0.004972   \n",
       "24          0.004712      0.020305      0.002283      0.000768       0.001160   \n",
       "25          0.000304      0.000227      0.000129      0.000206       0.000259   \n",
       "26          0.006869      0.000286      0.000263      0.000473       0.003635   \n",
       "27          0.000849      0.031654      0.006090      0.004463       0.003040   \n",
       "28          0.000347      0.002050      0.000247      0.000225       0.002766   \n",
       "29          0.000257      0.001711      0.003658      0.000295       0.000736   \n",
       "...              ...           ...           ...           ...            ...   \n",
       "102247      0.000183      0.000215      0.031078      0.000201       0.000991   \n",
       "102248      0.000441      0.000354      0.882987      0.000320       0.058030   \n",
       "102249      0.002184      0.000507      0.097589      0.000244       0.814016   \n",
       "102250      0.000227      0.000303      0.000280      0.000213       0.000359   \n",
       "102251      0.000167      0.000189      0.000142      0.000285       0.000266   \n",
       "102252      0.000715      0.000307      0.125178      0.000385       0.060553   \n",
       "102253      0.000204      0.000294      0.050338      0.000509       0.002941   \n",
       "102254      0.000897      0.001071      0.037506      0.000685       0.001380   \n",
       "102255      0.002959      0.010416      0.001370      0.007212       0.014985   \n",
       "102256      0.000489      0.000242      0.000239      0.000304       0.000889   \n",
       "102257      0.996174      0.000176      0.000126      0.000222       0.000257   \n",
       "102258      0.001097      0.010454      0.003710      0.002079       0.002563   \n",
       "102259      0.002842      0.001320      0.000171      0.014906       0.000366   \n",
       "102260      0.000431      0.000897      0.002560      0.000232       0.003679   \n",
       "102261      0.022570      0.011606      0.008826      0.003732       0.003191   \n",
       "102262      0.000781      0.007122      0.001104      0.000413       0.000567   \n",
       "102263      0.002049      0.050255      0.002075      0.002094       0.031398   \n",
       "102264      0.000325      0.000243      0.000143      0.000208       0.000248   \n",
       "102265      0.001287      0.000510      0.012405      0.000435       0.023503   \n",
       "102266      0.003682      0.009906      0.008803      0.006022       0.249928   \n",
       "102267      0.000269      0.000180      0.000135      0.000208       0.000256   \n",
       "102268      0.001007      0.001700      0.855179      0.001227       0.018682   \n",
       "102269      0.000596      0.025910      0.000728      0.000580       0.014079   \n",
       "102270      0.986916      0.000203      0.000169      0.000200       0.000494   \n",
       "102271      0.000217      0.000203      0.000124      0.000204       0.000241   \n",
       "102272      0.005877      0.005761      0.759140      0.003611       0.061904   \n",
       "102273      0.009569      0.597092      0.001582      0.001987       0.003911   \n",
       "102274      0.747059      0.000326      0.001567      0.000248       0.034813   \n",
       "102275      0.000288      0.001506      0.000323      0.000316       0.019457   \n",
       "102276      0.001101      0.000533      0.004701      0.000815       0.012756   \n",
       "\n",
       "        class_prob_11  class_prob_12  class_prob_13  class_prob_14  \\\n",
       "0            0.001770       0.000976       0.000614       0.000613   \n",
       "1            0.000426       0.001487       0.000343       0.000186   \n",
       "2            0.015374       0.043277       0.674879       0.005587   \n",
       "3            0.000226       0.000319       0.000299       0.000133   \n",
       "4            0.000996       0.000768       0.001649       0.012623   \n",
       "5            0.009018       0.006934       0.001465       0.000992   \n",
       "6            0.000976       0.007860       0.001686       0.003009   \n",
       "7            0.004696       0.009411       0.030359       0.004425   \n",
       "8            0.000597       0.000672       0.000638       0.000140   \n",
       "9            0.008002       0.515543       0.023741       0.001925   \n",
       "10           0.000349       0.000682       0.002352       0.315227   \n",
       "11           0.006503       0.015317       0.030274       0.000657   \n",
       "12           0.000211       0.000498       0.000702       0.000201   \n",
       "13           0.003031       0.100095       0.837777       0.002517   \n",
       "14           0.000275       0.000299       0.000272       0.000175   \n",
       "15           0.000309       0.000333       0.000293       0.000147   \n",
       "16           0.000194       0.000314       0.000287       0.000121   \n",
       "17           0.000243       0.000329       0.000270       0.000106   \n",
       "18           0.007310       0.339740       0.001218       0.000250   \n",
       "19           0.000271       0.001495       0.001253       0.635491   \n",
       "20           0.000211       0.000296       0.000273       0.000126   \n",
       "21           0.358461       0.262274       0.100263       0.004576   \n",
       "22           0.000225       0.000329       0.000291       0.000135   \n",
       "23           0.062489       0.008563       0.017213       0.010120   \n",
       "24           0.000544       0.006210       0.002683       0.001696   \n",
       "25           0.027463       0.000379       0.000276       0.000121   \n",
       "26           0.000487       0.311241       0.001302       0.000148   \n",
       "27           0.002848       0.005438       0.004882       0.010956   \n",
       "28           0.001208       0.025854       0.000999       0.000324   \n",
       "29           0.000262       0.000530       0.000541       0.000303   \n",
       "...               ...            ...            ...            ...   \n",
       "102247       0.000164       0.000417       0.000359       0.000116   \n",
       "102248       0.000204       0.000548       0.023319       0.003453   \n",
       "102249       0.000173       0.000761       0.000815       0.000543   \n",
       "102250       0.000198       0.000403       0.000869       0.001362   \n",
       "102251       0.000244       0.000863       0.000287       0.000121   \n",
       "102252       0.000231       0.001248       0.002048       0.000491   \n",
       "102253       0.000595       0.001889       0.004615       0.000249   \n",
       "102254       0.000350       0.002730       0.001450       0.001129   \n",
       "102255       0.025164       0.019383       0.014961       0.698647   \n",
       "102256       0.000949       0.002008       0.013022       0.003049   \n",
       "102257       0.000182       0.000610       0.000271       0.000106   \n",
       "102258       0.003104       0.875027       0.005287       0.002308   \n",
       "102259       0.095305       0.025753       0.001324       0.000954   \n",
       "102260       0.001080       0.002327       0.053847       0.903328   \n",
       "102261       0.139468       0.132251       0.050964       0.004144   \n",
       "102262       0.000496       0.001630       0.001141       0.001841   \n",
       "102263       0.002279       0.832055       0.003897       0.002812   \n",
       "102264       0.001037       0.001168       0.000286       0.000147   \n",
       "102265       0.001351       0.048597       0.006126       0.688654   \n",
       "102266       0.018085       0.019245       0.016842       0.019672   \n",
       "102267       0.000235       0.003818       0.000282       0.000115   \n",
       "102268       0.001573       0.001159       0.043407       0.001723   \n",
       "102269       0.000387       0.001096       0.008612       0.702694   \n",
       "102270       0.000393       0.001698       0.000301       0.000132   \n",
       "102271       0.000412       0.000453       0.000273       0.000127   \n",
       "102272       0.000702       0.002087       0.095558       0.003425   \n",
       "102273       0.011019       0.326504       0.007682       0.002493   \n",
       "102274       0.000210       0.001051       0.000582       0.000180   \n",
       "102275       0.000319       0.000629       0.000669       0.962072   \n",
       "102276       0.001491       0.003171       0.835382       0.094020   \n",
       "\n",
       "        class_prob_15  class_prob_16  class_prob_17  class_prob_18  \\\n",
       "0            0.000310       0.000070       0.000260       0.000324   \n",
       "1            0.000174       0.000054       0.000215       0.000347   \n",
       "2            0.008171       0.000305       0.007258       0.005865   \n",
       "3            0.000169       0.000053       0.000230       0.000154   \n",
       "4            0.001140       0.000132       0.000462       0.000778   \n",
       "5            0.000831       0.000456       0.000345       0.004316   \n",
       "6            0.900470       0.000592       0.001519       0.007326   \n",
       "7            0.008250       0.000220       0.084286       0.032652   \n",
       "8            0.000178       0.000051       0.000194       0.000205   \n",
       "9            0.000579       0.000924       0.001923       0.018156   \n",
       "10           0.000551       0.000760       0.000935       0.000711   \n",
       "11           0.003365       0.000189       0.001973       0.020436   \n",
       "12           0.000276       0.000077       0.000251       0.000252   \n",
       "13           0.000534       0.000268       0.000443       0.002239   \n",
       "14           0.998291       0.000043       0.000217       0.000197   \n",
       "15           0.000183       0.000049       0.000198       0.994893   \n",
       "16           0.000194       0.000045       0.000209       0.000170   \n",
       "17           0.000184       0.000041       0.000195       0.000180   \n",
       "18           0.000642       0.000369       0.000718       0.000595   \n",
       "19           0.000673       0.000066       0.475100       0.000292   \n",
       "20           0.000175       0.000043       0.000199       0.000231   \n",
       "21           0.035627       0.000412       0.006640       0.004942   \n",
       "22           0.000183       0.000064       0.000211       0.000138   \n",
       "23           0.001528       0.000065       0.002247       0.001221   \n",
       "24           0.001029       0.000115       0.004890       0.010684   \n",
       "25           0.988296       0.000048       0.000211       0.000184   \n",
       "26           0.000172       0.001476       0.000307       0.000743   \n",
       "27           0.522012       0.000155       0.507260       0.001550   \n",
       "28           0.000365       0.000364       0.000318       0.000529   \n",
       "29           0.000248       0.000076       0.000431       0.056011   \n",
       "...               ...            ...            ...            ...   \n",
       "102247       0.000168       0.957709       0.000303       0.000215   \n",
       "102248       0.000362       0.000391       0.000454       0.000917   \n",
       "102249       0.000193       0.040266       0.000322       0.000347   \n",
       "102250       0.000202       0.000076       0.001528       0.000163   \n",
       "102251       0.000162       0.000047       0.000215       0.992607   \n",
       "102252       0.000393       0.750395       0.000308       0.001369   \n",
       "102253       0.000235       0.000254       0.000474       0.926154   \n",
       "102254       0.000417       0.000467       0.004143       0.001398   \n",
       "102255       0.041467       0.000110       0.010326       0.005929   \n",
       "102256       0.000476       0.001898       0.000806       0.001617   \n",
       "102257       0.000170       0.000048       0.000193       0.000137   \n",
       "102258       0.000416       0.007769       0.001139       0.001306   \n",
       "102259       0.791936       0.000058       0.000550       0.001764   \n",
       "102260       0.000296       0.000432       0.000819       0.000253   \n",
       "102261       0.042260       0.000206       0.003634       0.063100   \n",
       "102262       0.001059       0.000186       0.038965       0.001712   \n",
       "102263       0.000666       0.000205       0.001315       0.001076   \n",
       "102264       0.995670       0.000046       0.000205       0.000206   \n",
       "102265       0.004393       0.000845       0.002003       0.002393   \n",
       "102266       0.224741       0.000560       0.004202       0.030618   \n",
       "102267       0.000164       0.000076       0.000211       0.000212   \n",
       "102268       0.000811       0.000113       0.002278       0.001262   \n",
       "102269       0.002068       0.000237       0.003399       0.001478   \n",
       "102270       0.000180       0.000054       0.000196       0.000200   \n",
       "102271       0.998145       0.000045       0.000191       0.000155   \n",
       "102272       0.002524       0.000130       0.001336       0.018718   \n",
       "102273       0.002912       0.000516       0.001545       0.003806   \n",
       "102274       0.000192       0.000116       0.000281       0.000159   \n",
       "102275       0.005702       0.000439       0.001083       0.001010   \n",
       "102276       0.001395       0.000116       0.001995       0.002616   \n",
       "\n",
       "        class_prob_19  \n",
       "0            0.000731  \n",
       "1            0.000537  \n",
       "2            0.024633  \n",
       "3            0.000491  \n",
       "4            0.002011  \n",
       "5            0.003913  \n",
       "6            0.033831  \n",
       "7            0.567641  \n",
       "8            0.000327  \n",
       "9            0.078827  \n",
       "10           0.003585  \n",
       "11           0.024996  \n",
       "12           0.000839  \n",
       "13           0.012250  \n",
       "14           0.000362  \n",
       "15           0.002526  \n",
       "16           0.000396  \n",
       "17           0.000314  \n",
       "18           0.001749  \n",
       "19           0.005774  \n",
       "20           0.000567  \n",
       "21           0.056439  \n",
       "22           0.000374  \n",
       "23           0.060520  \n",
       "24           0.037148  \n",
       "25           0.000468  \n",
       "26           0.004006  \n",
       "27           0.007748  \n",
       "28           0.002899  \n",
       "29           0.922620  \n",
       "...               ...  \n",
       "102247       0.000363  \n",
       "102248       0.002504  \n",
       "102249       0.000774  \n",
       "102250       0.000811  \n",
       "102251       0.004398  \n",
       "102252       0.000760  \n",
       "102253       0.009977  \n",
       "102254       0.005453  \n",
       "102255       0.037494  \n",
       "102256       0.001190  \n",
       "102257       0.000275  \n",
       "102258       0.052710  \n",
       "102259       0.022199  \n",
       "102260       0.000757  \n",
       "102261       0.397146  \n",
       "102262       0.032211  \n",
       "102263       0.025870  \n",
       "102264       0.000426  \n",
       "102265       0.009226  \n",
       "102266       0.263080  \n",
       "102267       0.000354  \n",
       "102268       0.002883  \n",
       "102269       0.003947  \n",
       "102270       0.000325  \n",
       "102271       0.000351  \n",
       "102272       0.036094  \n",
       "102273       0.106505  \n",
       "102274       0.000847  \n",
       "102275       0.001198  \n",
       "102276       0.008217  \n",
       "\n",
       "[102277 rows x 19 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63021084, 0.00073022, 0.12938255, 0.08233588, 0.38772137,\n",
       "       0.35054736, 0.06010154, 0.0162588 , 0.35044424, 0.36899349,\n",
       "       0.33343102, 0.00718196, 0.00099249, 0.13392986, 0.03079003,\n",
       "       0.40782321, 0.38772949, 0.11120969, 0.07217844, 0.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10306741, 0.21446534, 0.09234781, 0.1665037 , 0.77700784,\n",
       "       0.20140753, 0.09591953, 0.09388762, 0.21980566, 0.2528162 ,\n",
       "       0.18957717, 0.15716459, 0.16162135, 0.08285841, 0.18494502,\n",
       "       0.15308998, 0.16854106, 0.1316501 , 0.07221129])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.delete(a, -1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= pickle.load(open('../feature/stacking_pkl_file/2leve_lgb_stacking3.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pickle.load(open('../feature/stacking_pkl_file/rnn_model_bagging2.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102277, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../feature/2leve_lgb_stacking3.pkl','wb') as fout:\n",
    "    pickle.dump([a,b],fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102277, 19)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.01716689e-04, 6.16839170e-05, 7.57186936e-05, 1.06231030e-03,\n",
       "       9.96983826e-01, 3.12459830e-04, 6.37228004e-05, 1.02987576e-06,\n",
       "       2.93245284e-05, 1.16468422e-04, 1.56775292e-04, 3.49557318e-04,\n",
       "       1.02049326e-05, 3.78012592e-05, 1.93889423e-06, 1.43233101e-05,\n",
       "       1.13495912e-06, 1.05727275e-04, 1.42806357e-05], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.51418984e-04, 8.59006145e-05, 5.72015080e-05, 9.98149313e-01,\n",
       "       2.16004989e-05, 2.21425307e-05, 1.92076409e-05, 2.88491225e-05,\n",
       "       4.80360194e-05, 6.77559877e-05, 1.46532588e-04, 8.52455299e-05,\n",
       "       1.89921750e-05, 8.53312692e-06, 1.33990754e-05, 7.04179440e-06,\n",
       "       1.30948036e-05, 1.99016595e-05, 7.09543232e-05, 0.00000000e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

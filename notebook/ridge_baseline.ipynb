{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from keras.utils import np_utils\n",
    "import pickle\n",
    "from sklearn.linear_model import Ridge\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_dir = '../feature/svd_5.pkl'\n",
    "tifi_dir = '../feature/tifi_min4.pkl'\n",
    "pro_output = '../10fold_pro/10foldprob_ridge_baseline.csv'\n",
    "output = '../output/prob_ridge_baseline2.csv'\n",
    "modify_tifi = False\n",
    "modefi_svd = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "train = pd.read_csv('../input/new_data/train_set.csv')\n",
    "test = pd.read_csv('../input/new_data/test_set.csv')\n",
    "test_id = pd.read_csv('../input/new_data/test_set.csv')[[\"id\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/check.py:17: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "y=(train[\"class\"]-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test])\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "train_offset = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modefi_svd:\n",
    "    all_text_svd = []\n",
    "    column=\"article\"\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2),min_df=4, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1)\n",
    "    full_article = vec.fit_transform(all_data[column])\n",
    "    test_article = vec.transform(test[column])\n",
    "    train_article = vec.transform(train[column])\n",
    "\n",
    "    ### SVD Components ###\n",
    "    n_comp = 5\n",
    "    svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "    svd_obj.fit(full_article)\n",
    "    train_svd = pd.DataFrame(svd_obj.transform(train_article))\n",
    "    test_svd = pd.DataFrame(svd_obj.transform(test_article))\n",
    "    train_svd.columns = ['svd_params_'+str(i+1) for i in range(n_comp)]\n",
    "    test_svd.columns = ['svd_params_'+str(i+1) for i in range(n_comp)]\n",
    "    all_text_svd.extend(train_svd.columns)\n",
    "    train = pd.concat([train, train_svd], axis=1)\n",
    "    test = pd.concat([test, test_svd], axis=1)\n",
    "    del full_article, train_article, test_article\n",
    "    name = ['svd_params_'+str(i+1) for i in range(n_comp)]\n",
    "    train_svd = csr_matrix(pd.get_dummies(train[name],\n",
    "                                          sparse=True).values)\n",
    "    test_svd = csr_matrix(pd.get_dummies(test[name],\n",
    "                                          sparse=True).values)\n",
    "    with open(svd_dir,'wb') as fout:\n",
    "        pickle.dump([train_svd,test_svd],fout)\n",
    "else:\n",
    "    train_svd, test_svd= pickle.load(open(svd_dir,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modify_tifi:\n",
    "    column=\"word_seg\"\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2),min_df=4, max_df=0.9,use_idf=1,smooth_idf=1, sublinear_tf=1)\n",
    "    trn_term_doc = vec.fit_transform(train[column])\n",
    "    test_term_doc = vec.transform(test[column])\n",
    "    with open(tifi_dir,'wb') as fout:\n",
    "        pickle.dump([trn_term_doc,test_term_doc],fout)\n",
    "else:\n",
    "     trn_term_doc, test_term_doc= pickle.load(open(tifi_dir,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack((trn_term_doc, train_svd)).tocsr()\n",
    "X_test = hstack((test_term_doc, test_svd)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"class_prob_%s\"%i for i in range(1,20)]\n",
    "one_y_train=np_utils.to_categorical(y,num_classes=20)\n",
    "# one_y_val=np_utils.to_categorical(Y_valid,num_classes=20)\n",
    "test_prob = pd.DataFrame([],columns=[\"class_prob_%s\"%i for i in range(1,20)])\n",
    "train_prob = pd.DataFrame([],columns=[\"class_prob_%s\"%i for i in range(1,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [21:50<00:00, 65.52s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(20)):\n",
    "    model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205)\n",
    "    model.fit(X_train, one_y_train[:,i])\n",
    "    test_prob['class_prob_%s'%(i+1)] = model.predict(X_test)\n",
    "    train_prob['class_prob_%s'%(i+1)] = model.predict(X_train)\n",
    "\n",
    "# val_result = np.argmax(test_prob[name].values,axis=1)\n",
    "# print ('score is {}'.format(f1_score(Y_valid, val_result, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prob=pd.DataFrame(test_pred)\n",
    "# test_prob.columns=[\"class_prob_%s\"%i for i in range(1,20)]\n",
    "test_prob[\"id\"]=list(test_id[\"id\"])\n",
    "test_prob.to_csv(pro_output,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102277, 1)\n",
      "(102277, 1)\n",
      "time use: 1486.0870008468628\n"
     ]
    }
   ],
   "source": [
    "preds=np.argmax(test_prob[name].values,axis=1)\n",
    "test_pred=pd.DataFrame(preds)\n",
    "test_pred.columns=[\"class\"]\n",
    "test_pred[\"class\"]=(test_pred[\"class\"]+1).astype(int)\n",
    "print(test_pred.shape)\n",
    "print(test_id.shape)\n",
    "test_pred[\"id\"]=list(test_id[\"id\"])\n",
    "test_pred[[\"id\",\"class\"]].to_csv(output,index=None)\n",
    "t2=time.time()\n",
    "print(\"time use:\",t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../feature/stackint_pkl_file/ridge.pkl','wb') as fout:\n",
    "    pickle.dump([train_prob,test_prob],fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../feature/stackint_pkl_file/lr.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e53a9455b70e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../feature/stackint_pkl_file/lr.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../feature/stackint_pkl_file/lr.pkl'"
     ]
    }
   ],
   "source": [
    "a,b = pickle.load(open('../feature/stackint_pkl_file/lr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

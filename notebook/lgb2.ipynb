{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/check.py:17: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('../input/train2.csv')\n",
    "test = pd.read_csv('../input/test2.csv')\n",
    "test_id = pd.read_csv('../input/new_data/test_set.csv')[[\"id\"]].copy()\n",
    "y=(train[\"class\"]-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_term_doc = sparse.load_npz('../feature/text_tifi/trn_term_doc.npz')\n",
    "# trn_term_word = sparse.load_npz('../feature/text_tifi/trn_term_word.npz')\n",
    "# trn_term_word_three = sparse.load_npz('../feature/text_tifi/trn_term_word_three.npz')\n",
    "# train_feaure =  hstack([trn_term_doc,trn_term_word,trn_term_word_three]).tocsr()\n",
    "# del trn_term_doc,trn_term_word,trn_term_word_three\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# trn_term_word_four = sparse.load_npz('../feature/text_tifi/trn_term_word_four.npz')\n",
    "# # trn_term_word_five = sparse.load_npz('../feature/text_tifi/trn_term_word_five.npz')\n",
    "# trn_char = sparse.load_npz('../feature/text_tifi/trn_char.npz')\n",
    "# docLen  =pd.DataFrame( np.array(train[column].map(lambda x : len(x.split(\" \")))/39759).reshape(-1,1))\n",
    "# doclen_word = pd.DataFrame( np.array(train['article'].map(lambda x : len(x.split(\" \")))/train[column].map(lambda x : len(x.split(\" \")))).reshape(-1,1))\n",
    "# docLen_test  =pd.DataFrame( np.array(test[column].map(lambda x : len(x.split(\" \")))/39759).reshape(-1,1))\n",
    "# doclen_word_test = pd.DataFrame( np.array(test['article'].map(lambda x : len(x.split(\" \")))/test[column].map(lambda x : len(x.split(\" \")))).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "one_y_train=np_utils.to_categorical(y,num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feaure =  hstack([train_feaure, trn_term_word_four,trn_char,doclen_word]).tocsr()\n",
    "# del trn_term_word_four,trn_char,doclen_word\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_feaure.shape\n",
    "import pickle\n",
    "svd_dir = '../feature/svd_5.pkl'\n",
    "tifi_dir = '../feature/tifi_min4.pkl'\n",
    "train_svd, test_svd= pickle.load(open(svd_dir,'rb'))\n",
    "trn_term_doc, test_term_doc= pickle.load(open(tifi_dir,'rb'))\n",
    "lda1 = pd.read_csv('../feature/other_features/features-vinson/ldaFeature10.csv')\n",
    "lda2 = pd.read_csv('../feature/other_features/features-vinson/ldaFeature20.csv')\n",
    "lda3 = pd.read_csv('../feature/other_features/features-vinson/ldaFeature30.csv')\n",
    "lda4 = pd.read_csv('../feature/other_features/features-vinson/ldaFeature40.csv')\n",
    "test_term_doc = sparse.load_npz('../feature/text_tifi/test_term_doc.npz')\n",
    "trn_term_doc = sparse.load_npz('../feature/text_tifi/trn_term_doc.npz')\n",
    "train_feaure = hstack((trn_term_doc, train_svd, lda1.iloc[:102277,:], lda2.iloc[:102277,:], lda3.iloc[:102277,:], lda4.iloc[:102277,:], trn_term_doc)).tocsr()\n",
    "test_festure = hstack((test_term_doc, test_svd, lda1.iloc[102277:,:], lda2.iloc[102277:,:], lda3.iloc[102277:,:], lda4.iloc[102277:,:], test_term_doc)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_term_doc = sparse.load_npz('../feature/text_tifi/test_term_doc.npz')\n",
    "# test_term_word = sparse.load_npz('../feature/text_tifi/test_term_word.npz')\n",
    "# test_term_word_three = sparse.load_npz('../feature/text_tifi/test_term_word_three.npz')\n",
    "# test_term_word_four = sparse.load_npz('../feature/text_tifi/test_term_word_four.npz')\n",
    "# # test_term_word_five = sparse.load_npz('../feature/text_tifi/test_term_word_five.npz')\n",
    "# test_char = sparse.load_npz('../feature/text_tifi/test_char.npz')\n",
    "# test_festure =  hstack([test_term_doc,test_term_word,test_term_word_three,test_term_word_four,test_char,doclen_word_test]).tocsr()\n",
    "# del test_term_doc,test_term_word,test_term_word_three,test_term_word_four,test_char,doclen_word_test\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = pd.DataFrame([],columns=[\"class_prob_%s\"%i for i in range(1,20)])\n",
    "train_prob = pd.DataFrame([],columns=[\"class_prob_%s\"%i for i in range(1,20)])\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return 'f1', f1_score(y_true, y_hat, average='macro'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(102277, 800105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102277, 290513)\n"
     ]
    }
   ],
   "source": [
    "for i in range(19):\n",
    "    print(i)\n",
    "    train_target = one_y_train[:,i]\n",
    "    model = LogisticRegression(C=4, solver='sag')\n",
    "    sfm = SelectFromModel(model, threshold=0.1)\n",
    "    print(train_feaure.shape)\n",
    "    train_sparse_matrix = sfm.fit_transform(train_feaure, train_target)\n",
    "    print(train_sparse_matrix.shape)\n",
    "    train_sparse_matrix, valid_sparse_matrix, y_train, y_valid = train_test_split(train_sparse_matrix, train_target, test_size=0.05, random_state=144)\n",
    "    test_sparse_matrix = sfm.transform(test_festure)\n",
    "    d_train = lgb.Dataset(train_sparse_matrix, label=y_train)\n",
    "    d_valid = lgb.Dataset(valid_sparse_matrix, label=y_valid)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    params = {'learning_rate': 0.1,\n",
    "              'application': 'binary',\n",
    "              'num_leaves': 50,\n",
    "              'max_depth': 6,\n",
    "              'verbosity': -1,\n",
    "              'metric': 'auc',\n",
    "              'data_random_seed': 2,\n",
    "              'bagging_fraction': 0.8,\n",
    "              'feature_fraction': 0.6,\n",
    "              'nthread': 4,}\n",
    "    model = lgb.train(params,\n",
    "                      feval=lgb_f1_score,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      verbose_eval=10,\n",
    "                      early_stopping_rounds=200)\n",
    "    train_prob['class_prob_%s'%(i+1)] = model.predict(valid_sparse_matrix)\n",
    "    test_prob['class_prob_%s'%(i+1)] = model.predict(test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

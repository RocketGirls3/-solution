{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/randomstate-1.14.0-py3.5-linux-x86_64.egg/randomstate/__init__.py:66: RandomStateDeprecationWarning: \n",
      "**End-of-life notification**\n",
      "\n",
      "This library was designed to bring alternative generators to the NumPy \n",
      "infrastructure. It as been successful in advancing the conversation \n",
      "for a future implementation of a new random number API in NumPy which \n",
      "will allow new algorithms and/or generators. The next step\n",
      "in this process is to separate the basic (or core RNG) from the \n",
      "functions that transform random bits into useful random numbers.\n",
      "This has been implemented in a successor project  **randomgen** \n",
      "available on GitHub\n",
      "\n",
      "https://github.com/bashtage/randomgen\n",
      "\n",
      "or PyPi\n",
      "\n",
      "https://pypi.org/project/randomstate/.\n",
      "\n",
      "randomgen has a slightly different API, so please see the randomgen documentation\n",
      "\n",
      "https://bashtage.github.io/randomgen.\n",
      "\n",
      "  warnings.warn(DEPRECATION_MESSAGE, RandomStateDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from wordbatch.extractors import WordHash, WordBag\n",
    "from wordbatch.models import FM_FTRL,FTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/check.py:17: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "column = \"word_seg\"\n",
    "train = pd.read_csv('../input/new_data/train_set.csv')\n",
    "test = pd.read_csv('../input/new_data/test_set.csv')\n",
    "test_id = test[\"id\"].copy()\n",
    "y_all = (pd.Series(train['class'])-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_term_doc = sparse.load_npz('../feature/text_tifi/trn_term_doc.npz')\n",
    "trn_term_word = sparse.load_npz('../feature/text_tifi/trn_term_word.npz')\n",
    "trn_term_word_three = sparse.load_npz('../feature/text_tifi/trn_term_word_three.npz')\n",
    "train_feaure =  hstack([trn_term_doc,trn_term_word,trn_term_word_three]).tocsr()\n",
    "del trn_term_doc,trn_term_word,trn_term_word_three\n",
    "import gc\n",
    "gc.collect()\n",
    "trn_term_word_four = sparse.load_npz('../feature/text_tifi/trn_term_word_four.npz')\n",
    "# trn_term_word_five = sparse.load_npz('../feature/text_tifi/trn_term_word_five.npz')\n",
    "trn_char = sparse.load_npz('../feature/text_tifi/trn_char.npz')\n",
    "docLen  =pd.DataFrame( np.array(train[column].map(lambda x : len(x.split(\" \")))/39759).reshape(-1,1))\n",
    "doclen_word = pd.DataFrame( np.array(train['article'].map(lambda x : len(x.split(\" \")))/train[column].map(lambda x : len(x.split(\" \")))).reshape(-1,1))\n",
    "docLen_test  =pd.DataFrame( np.array(test[column].map(lambda x : len(x.split(\" \")))/39759).reshape(-1,1))\n",
    "doclen_word_test = pd.DataFrame( np.array(test['article'].map(lambda x : len(x.split(\" \")))/test[column].map(lambda x : len(x.split(\" \")))).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "one_y_train=np_utils.to_categorical(y_all,num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feaure =  hstack([train_feaure, trn_term_word_four,trn_char,doclen_word]).tocsr()\n",
    "del trn_term_word_four,trn_char,doclen_word\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_term_doc = sparse.load_npz('../feature/text_tifi/test_term_doc.npz')\n",
    "test_term_word = sparse.load_npz('../feature/text_tifi/test_term_word.npz')\n",
    "test_term_word_three = sparse.load_npz('../feature/text_tifi/test_term_word_three.npz')\n",
    "test_term_word_four = sparse.load_npz('../feature/text_tifi/test_term_word_four.npz')\n",
    "# test_term_word_five = sparse.load_npz('../feature/text_tifi/test_term_word_five.npz')\n",
    "test_char = sparse.load_npz('../feature/text_tifi/test_char.npz')\n",
    "test_festure =  hstack([test_term_doc,test_term_word,test_term_word_three,test_term_word_four,test_char,doclen_word_test]).tocsr()\n",
    "del test_term_doc,test_term_word,test_term_word_three,test_term_word_four,test_char,doclen_word_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(train_feaure, y_all, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"class_prob_%s\"%i for i in range(1,20)]\n",
    "one_y_train=np_utils.to_categorical(Y_train,num_classes=20)\n",
    "one_y_val=np_utils.to_categorical(Y_valid,num_classes=20)\n",
    "test_prob = pd.DataFrame([],columns=[\"class_prob_%s\"%i for i in range(1,20)])\n",
    "val_prob = pd.DataFrame([],columns=[\"class_prob_%s\"%i for i in range(1,20)])\n",
    "train_prob = pd.DataFrame([],columns=[\"class_prob_%s\"%i for i in range(1,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_f1_score(y_hat, data):\n",
    "    y_true = data\n",
    "    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    return f1_score(y_true, y_hat, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(20)):\n",
    "    model = FM_FTRL(alpha=0.01, beta=0.01, L1=0.00001, L2=0.1, D=trn_term_doc.shape[1], alpha_fm=0.01, L2_fm=0.0, init_fm=0.01,\n",
    "                    D_fm=100, e_noise=0.0001, iters=17, inv_link=\"identity\", threads=4)\n",
    "\n",
    "    model.fit(trn_term_doc, one_y_train[:,i])\n",
    "\n",
    "    test_prob['class_prob_%s'%(i+1)] = model.predict(test_term_doc)\n",
    "    train_prob['class_prob_%s'%(i+1)] = model.predict(trn_term_doc)\n",
    "    print (\"this list score is {}\".format(ridge_f1_score(val_prob.iloc[:,i], one_y_val[:,i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
